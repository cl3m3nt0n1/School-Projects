{"cells":[{"cell_type":"markdown","metadata":{"id":"TE-LZ77ZfZCY"},"source":["### Imports"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"_BuZxAw4fmeT"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3CsrR_MmfZCb"},"outputs":[],"source":["from urllib.request import urlopen\n","from PIL import Image\n","import torch\n","from transformers import AutoFeatureExtractor, ResNetForImageClassification, ResNetModel\n","import os\n","from PIL import Image\n","from torch.utils.data import TensorDataset, DataLoader\n","import time\n","import numpy as np\n","device = 'cuda'"]},{"cell_type":"markdown","metadata":{"id":"n-z2p2e1fZCe"},"source":["### Load Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4VFBMQTvfZCe"},"outputs":[],"source":["# Chemin du répertoire racine\n","root_dir = '/content/drive/MyDrive/ColabNotebooks/Dataset_1'\n","\n","# Dictionnaire pour stocker les images par sous-dossier\n","image_dict = {}\n","\n","# Parcourir tous les sous-dossiers\n","for root, dirs, files in os.walk(root_dir):\n","    for file in files:\n","        # Construire le chemin complet du fichier\n","        file_path = os.path.join(root, file)\n","\n","        # Vérifier si le fichier est une image en fonction de l'extension (par exemple, .png)\n","        if file_path.lower().endswith(('.png', '.jpg', '.jpeg', '.gif')):\n","            # Ouvrir l'image avec Pillow\n","            image = Image.open(file_path)\n","\n","            # Convertir l'image en format JPG (si elle n'est pas déjà en JPG)\n","            if image.format != \"JPEG\":\n","                image = image.convert(\"RGB\")\n","\n","            # Obtenez le nom du sous-dossier parent\n","            parent_dir = os.path.basename(os.path.dirname(file_path))\n","\n","            # Vérifiez si le sous-dossier existe dans le dictionnaire, sinon créez-le\n","            if parent_dir not in image_dict:\n","                image_dict[parent_dir] = []\n","\n","            # Ajouter l'image à la liste du sous-dossier correspondant\n","            image = image.crop((54, 34, 390, 253))\n","            image_dict[parent_dir].append(np.array(image))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_M5BfFj4fZCf"},"outputs":[],"source":["blues_list = image_dict['blues']\n","classical_list_GTZAN = image_dict['classical']\n","country_list = image_dict['country']\n","disco_list = image_dict['disco']\n","hiphop_list = image_dict['hiphop']\n","jazz_list = image_dict['jazz']\n","metal_list = image_dict['metal']\n","pop_list = image_dict['pop']\n","reggae_list = image_dict['reggae']\n","rock_list = image_dict['rock']\n"]},{"cell_type":"markdown","metadata":{"id":"3DgFG75yfZCg"},"source":["### Load the model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P88-WkrdfZCg"},"outputs":[],"source":["image_processor = AutoFeatureExtractor.from_pretrained(\"microsoft/resnet-18\")\n","model = ResNetForImageClassification.from_pretrained(\"microsoft/resnet-18\")"]},{"cell_type":"markdown","metadata":{"id":"j1BIOgwOfZCg"},"source":["### Testing the model's prediction on data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bs1Us7QLfZCh"},"outputs":[],"source":["inputs = image_processor(blues_list[0], return_tensors=\"pt\")\n","\n","print(inputs)\n","\n","with torch.no_grad():\n","    logits = model(**inputs).logits\n","\n","# model predicts one of the 1000 ImageNet classes\n","predicted_label = logits.argmax(-1).item()\n","print(model.config.id2label[predicted_label])"]},{"cell_type":"markdown","metadata":{"id":"lwsgDN9pfZCh"},"source":["Of course it is a theater curtain.\n","\n","### Fine tuning the model for our classes"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6lhQSPjnfZCh"},"outputs":[],"source":["num_each_class_sample=min(len(blues_list),len(classical_list_GTZAN),len(country_list),len(hiphop_list),len(jazz_list),len(pop_list),len(reggae_list),len(rock_list),len(metal_list),len(disco_list))\n","\n","# Concaténez les listes verticalement (le long de l'axe 0)\n","tensor_x = torch.Tensor(np.concatenate((blues_list[:num_each_class_sample],\n","                                       classical_list_GTZAN[:num_each_class_sample],\n","                                       disco_list[:num_each_class_sample],\n","                                       country_list[:num_each_class_sample],\n","                                       hiphop_list[:num_each_class_sample],\n","                                       jazz_list[:num_each_class_sample],\n","                                       metal_list[:num_each_class_sample],\n","                                       pop_list[:num_each_class_sample],\n","                                       reggae_list[:num_each_class_sample],\n","                                       rock_list[:num_each_class_sample]), axis=0)).to(device)\n","\n","tensor_y = torch.Tensor(np.concatenate((np.full(num_each_class_sample, 0),\n","                                       np.full(num_each_class_sample,  1),\n","                                       np.full(num_each_class_sample,  2),\n","                                       np.full(num_each_class_sample,  3),\n","                                       np.full(num_each_class_sample,  4),\n","                                       np.full(num_each_class_sample,  5),\n","                                       np.full(num_each_class_sample,  6),\n","                                       np.full(num_each_class_sample,  7),\n","                                       np.full(num_each_class_sample,  8),\n","                                       np.full(num_each_class_sample,  9)), axis=0)).to(device)\n","\n","\n","my_dataset = TensorDataset(tensor_x,tensor_y) # create your datset\n","my_dataloader = DataLoader(my_dataset,batch_size=10, shuffle=True) # create your dataloader\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"durN6kYgfZCi"},"outputs":[],"source":["def train(net, train_dataloader, criterion, optimizer, scheduler=None, epochs=10, device=device, checkpoint_epochs=2):\n","    start = time.time()\n","    print(f'Training for {epochs} epochs on {device}')\n","\n","    for epoch in range(1,epochs+1):\n","        print(f\"Epoch {epoch}/{epochs}\")\n","\n","        net.train()  # put network in train mode for Dropout and Batch Normalization\n","        train_loss = torch.tensor(0., device=device)  # loss and accuracy tensors are on the GPU to avoid data transfers\n","        train_accuracy = torch.tensor(0., device=device)\n","        for X, y in train_dataloader:\n","            X = X.to(device)\n","            y = y.type(torch.LongTensor).to(device)\n","            preds = net(X)\n","            loss = criterion(preds, y)\n","\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","            with torch.no_grad():\n","                train_loss += loss * train_dataloader.batch_size\n","                train_accuracy += (torch.argmax(preds, dim=1) == y).sum()\n","\n","        if scheduler is not None:\n","            scheduler.step()\n","\n","        print(f'Training loss: {train_loss/len(train_dataloader.dataset):.2f}')\n","        print(f'Training accuracy: {100*train_accuracy/len(train_dataloader.dataset):.2f}')\n","\n","\n","        if epoch%checkpoint_epochs==0:\n","            torch.save({\n","                'epoch': epoch,\n","                'state_dict': net.state_dict(),\n","                'optimizer': optimizer.state_dict(),\n","            }, './checkpoint.pth.tar')\n","\n","        print()\n","\n","    end = time.time()\n","    print(f'Total training time: {end-start:.1f} seconds')\n","    return net"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YclbeP16fZCi"},"outputs":[],"source":["from transformers import ResNetModel\n","import torch\n","\n","# model definition\n","class Classifier_model(torch.nn.Module):\n","    # define model elements\n","    def __init__(self):\n","        super(Classifier_model, self).__init__()\n","        self.device = device\n","        self.image_processor = AutoFeatureExtractor.from_pretrained(\"microsoft/resnet-18\",device=self.device)\n","        self.pre_trained_model = ResNetModel.from_pretrained(\"microsoft/resnet-18\")\n","        resnet18_output_size=25088\n","        self.fc = torch.nn.Linear(resnet18_output_size, 10)\n","        self.activation = torch.nn.ReLU()\n","\n","    # forward propagate input\n","    def forward(self, X):\n","        X = self.image_processor(X, return_tensors=\"pt\").to(self.device)\n","        # print(X.pixel_value.is_cuda)\n","        X = self.pre_trained_model(**X).last_hidden_state.flatten(start_dim=1)\n","        X = self.activation(X)\n","        X = self.fc(X)\n","\n","        return X.softmax(dim=1)\n","\n","    def features_extractor(self, X):\n","        X = self.image_processor(X, return_tensors=\"pt\").to(self.device)\n","        # print(X.pixel_value.is_cuda)\n","        X = self.pre_trained_model(**X).last_hidden_state.flatten(start_dim=1)\n","\n","        return X.softmax(dim=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rXnuKI-EfZCj"},"outputs":[],"source":["from transformers import ResNetModel\n","import torch\n","\n","# model definition\n","class Classifier_model_2(torch.nn.Module):\n","    # define model elements\n","    def __init__(self,f_model):\n","        super(Classifier_model_2, self).__init__()\n","        self.device = device\n","        resnet18_output_size=25088\n","        self.f_model = f_model\n","        self.fc = torch.nn.Linear(resnet18_output_size, 2)\n","        self.activation = torch.nn.ReLU()\n","\n","    # forward propagate input\n","    def forward(self, X):\n","        #X = self.image_processor(X, return_tensors=\"pt\").to(self.device)\n","        # print(X.pixel_value.is_cuda)\n","        X = self.f_model.features_extractor(X)\n","        X = self.activation(X)\n","        X = self.fc(X)\n","\n","        return X.softmax(dim=1)"]},{"cell_type":"markdown","metadata":{"id":"70zBBVKZfZCj"},"source":["### First Training\n","\n","Entrainement du modèle sur les données de GTZAN : 10 classes - 100 fichiers par classes"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wazu3EQLfZCj"},"outputs":[],"source":["# TRAINING 1\n","\n","lr, weight_decay, epochs = 1e-5, 5e-4, 10\n","\n","net = Classifier_model().to(device)\n","\n","# Standard CrossEntropy Loss for multi-class classification problems\n","loss = torch.nn.CrossEntropyLoss()\n","\n","optimizer = torch.optim.Adam(net.parameters(),lr=lr, weight_decay=weight_decay)\n","\n","net = train(net, my_dataloader, loss, optimizer, None, epochs, device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aEiLyFkyfZCk"},"outputs":[],"source":["torch.save(net, \"/content/drive/MyDrive/ColabNotebooks/model_10classes_Clem_Colab.pt\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P8MPfDInfZCk"},"outputs":[],"source":["\n","non_classical_list = np.concatenate((blues_list[:11], rock_list[:12], reggae_list[:11], country_list[:11], disco_list[:11], hiphop_list[:11], jazz_list[:11], metal_list[:11], pop_list[:11] ))\n","classical_list = classical_list_GTZAN\n","\n","\n","# Concaténez les listes verticalement (le long de l'axe 0)\n","tensor_x_2 = torch.Tensor(np.concatenate((classical_list,\n","                                       non_classical_list), axis=0)).to(device)\n","\n","tensor_y_2 = torch.Tensor(np.concatenate((np.full(len(classical_list), 0),\n","                                       np.full(len(non_classical_list),  1)), axis=0)).to(device)\n","\n","\n","my_dataset_2 = TensorDataset(tensor_x_2,tensor_y_2) # create your datset\n","my_dataloader_2 = DataLoader(my_dataset_2,batch_size=10, shuffle=True) # create your dataloader"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r_6lrXl_fZCk"},"outputs":[],"source":["# Chemin du répertoire racine\n","import random\n","root_dir = '/content/drive/MyDrive/ColabNotebooks/mel'\n","\n","# Dictionnaire pour stocker les images par sous-dossier\n","image_dict = {}\n","\n","# Parcourir tous les sous-dossiers\n","for root, dirs, files in os.walk(root_dir):\n","    for file in files:\n","        # Construire le chemin complet du fichier\n","        file_path = os.path.join(root, file)\n","\n","        # Vérifier si le fichier est une image en fonction de l'extension (par exemple, .png)\n","        if file_path.lower().endswith(('.png', '.jpg', '.jpeg', '.gif')):\n","            # Ouvrir l'image avec Pillow\n","            image = Image.open(file_path)\n","\n","            # Convertir l'image en format JPG (si elle n'est pas déjà en JPG)\n","            if image.format != \"JPEG\":\n","                image = image.convert(\"RGB\")\n","\n","            # Obtenez le nom du sous-dossier parent\n","            parent_dir = os.path.basename(os.path.dirname(file_path))\n","\n","            # Vérifiez si le sous-dossier existe dans le dictionnaire, sinon créez-le\n","            if parent_dir not in image_dict:\n","                image_dict[parent_dir] = []\n","\n","            # Ajouter l'image à la liste du sous-dossier correspondant\n","            image = image.resize((336,219))\n","            image_dict[parent_dir].append(np.array(image))\n","\n","classical_list_MG = image_dict['classic']\n","non_classical_list_MG = image_dict['non_classic']\n","\n","percent_classical_MG = int(0.2*len(classical_list_MG))\n","percent_non_classical_MG = int(0.2*len(non_classical_list_MG))\n","\n","\n","evaluation_list_dic = []\n","for sample in classical_list_MG[:percent_classical_MG]:\n","    buffer = []\n","    buffer.append(sample)\n","    buffer.append(0)\n","    evaluation_list_dic.append(buffer)\n","\n","for sample in non_classical_list_MG[:percent_non_classical_MG]:\n","    buffer = []\n","    buffer.append(sample)\n","    buffer.append(1)\n","    evaluation_list_dic.append(buffer)\n","\n","random.shuffle(evaluation_list_dic)\n","evaluation_list = []\n","for sample in evaluation_list_dic:\n","    evaluation_list.append(sample[0])\n","\n","activeL_classical_list = classical_list_MG[percent_classical_MG:]\n","activeL_non_classical_list = non_classical_list_MG[percent_non_classical_MG:]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4pVyyo6KfZCl"},"outputs":[],"source":["lr, weight_decay, epochs = 1e-5, 5e-4, 10\n","\n","net = torch.load(\"/content/drive/MyDrive/ColabNotebooks/model_10classes_Clem_Colab.pt\")\n","\n","net2 = Classifier_model_2(net).to(device)\n","\n","# Standard CrossEntropy Loss for multi-class classification problems\n","loss = torch.nn.CrossEntropyLoss()\n","\n","optimizer = torch.optim.Adam(net2.parameters(),lr=lr, weight_decay=weight_decay)\n","\n","net2 = train(net2, my_dataloader_2, loss, optimizer, None, epochs, device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7hf8_ZPofZCl"},"outputs":[],"source":["torch.save(net2, \"/content/drive/MyDrive/ColabNotebooks/model_2_Clem_trainings_longEgale_Colab.pt\")"]},{"cell_type":"markdown","metadata":{"id":"jTqBS9F_fZCl"},"source":["### Evaluation"]},{"cell_type":"code","source":["def Activedataloader(percent):\n","    tensor_x = torch.Tensor(np.concatenate((activeL_classical_list[:int(percent*len(activeL_classical_list))],\n","                                       non_classical_list_MG[:int(percent*len(activeL_non_classical_list))]), axis=0)).to(device)\n","\n","    tensor_y = torch.Tensor(np.concatenate((np.full(int(percent*len(activeL_classical_list)), 0),\n","                                       np.full(int(percent*len(activeL_non_classical_list)),  1)), axis=0)).to(device)\n","\n","\n","    my_dataset = TensorDataset(tensor_x,tensor_y) # create your datset\n","    my_dataloader = DataLoader(my_dataset,batch_size=10, shuffle=True)\n","    return my_dataloader\n"],"metadata":{"id":"mi-42fy5l9Os"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UeigJRRofZCl"},"outputs":[],"source":["torch.cuda.empty_cache()\n","\n","model = torch.load(\"model_2_Clem_trainings_longEgale_Colab.pt\")\n","model = model.eval()\n","\n","\n","test_data=torch.Tensor(np.array(evaluation_list)).to(device)\n","\n","preds = model(test_data)\n","\n","output=torch.argmax(preds, dim=1)\n","\n","count = 0\n","for i in range(0,len(output)):\n","    if output[i].item() == evaluation_list_dic[i][1]:\n","        count+=1\n","print(f\"Rand 20% accuracy : {(count/len(output))*100} %\")\n","print(output)"]},{"cell_type":"markdown","metadata":{"id":"J3Qs66Y7fZCm"},"source":["# Active Learning"]},{"cell_type":"markdown","metadata":{"id":"D4a8KkdxfZCm"},"source":["Dans cette partie, on cherche à déterminer quelle sera la stratégie la plus intéressante à utiliser en fonction du budget que l'on souhaite allouer au projet. Nous allons donc nous intéresser à plusieurs stratégies d'Active Learning. En parallèle, nous allons nous intéresser au pourcentage nécessaire, en fonction des stratégies sélectionnées, pour obtenir un taux de prédiction intéressant. Ceci aura pour effet de simuler le budget associé à chaque entraînement.  "]},{"cell_type":"code","source":["from urllib.request import urlopen\n","from PIL import Image\n","import torch\n","from transformers import AutoFeatureExtractor, ResNetForImageClassification, ResNetModel\n","import os\n","from PIL import Image\n","from torch.utils.data import TensorDataset, DataLoader\n","import time\n","import numpy as np\n","device = 'cuda'\n","from transformers import ResNetModel\n","import torch\n","\n","def train(net, train_dataloader, criterion, optimizer, scheduler=None, epochs=100, device=device, checkpoint_epochs=2, timeout=45):\n","    start = time.time()\n","    print(f'Training for {epochs} epochs on {device}')\n","\n","    for epoch in range(1,epochs+1):\n","        print(f\"Epoch {epoch}/{epochs}\")\n","\n","        net.train()  # put network in train mode for Dropout and Batch Normalization\n","        train_loss = torch.tensor(0., device=device)  # loss and accuracy tensors are on the GPU to avoid data transfers\n","        train_accuracy = torch.tensor(0., device=device)\n","        for X, y in train_dataloader:\n","            X = X.to(device)\n","            y = y.type(torch.LongTensor).to(device)\n","            preds = net(X)\n","            loss = criterion(preds, y)\n","\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","            with torch.no_grad():\n","                train_loss += loss * train_dataloader.batch_size\n","                train_accuracy += (torch.argmax(preds, dim=1) == y).sum()\n","\n","        if scheduler is not None:\n","            scheduler.step()\n","\n","        print(f'Training loss: {train_loss/len(train_dataloader.dataset):.2f}')\n","        print(f'Training accuracy: {100*train_accuracy/len(train_dataloader.dataset):.2f}')\n","\n","\n","        if epoch%checkpoint_epochs==0:\n","            torch.save({\n","                'epoch': epoch,\n","                'state_dict': net.state_dict(),\n","                'optimizer': optimizer.state_dict(),\n","            }, './checkpoint.pth.tar')\n","\n","        print()\n","        if((time.time() - start) >= timeout):\n","          break\n","\n","    end = time.time()\n","    print(f'Total training time: {end-start:.1f} seconds')\n","    return net\n","\n","# model definition\n","class Classifier_model(torch.nn.Module):\n","    # define model elements\n","    def __init__(self):\n","        super(Classifier_model, self).__init__()\n","        self.device = device\n","        self.image_processor = AutoFeatureExtractor.from_pretrained(\"microsoft/resnet-18\",device=self.device)\n","        self.pre_trained_model = ResNetModel.from_pretrained(\"microsoft/resnet-18\")\n","        resnet18_output_size=25088\n","        self.fc = torch.nn.Linear(resnet18_output_size, 10)\n","        self.activation = torch.nn.ReLU()\n","\n","    # forward propagate input\n","    def forward(self, X):\n","        X = self.image_processor(X, return_tensors=\"pt\").to(self.device)\n","        # print(X.pixel_value.is_cuda)\n","        X = self.pre_trained_model(**X).last_hidden_state.flatten(start_dim=1)\n","        X = self.activation(X)\n","        X = self.fc(X)\n","\n","        return X.softmax(dim=1)\n","\n","    def features_extractor(self, X):\n","        X = self.image_processor(X, return_tensors=\"pt\").to(self.device)\n","        # print(X.pixel_value.is_cuda)\n","        X = self.pre_trained_model(**X).last_hidden_state.flatten(start_dim=1)\n","\n","        return X.softmax(dim=1)\n","\n","# model definition\n","class Classifier_model_2(torch.nn.Module):\n","    # define model elements\n","    def __init__(self,f_model):\n","        super(Classifier_model_2, self).__init__()\n","        self.device = device\n","        resnet18_output_size=25088\n","        self.f_model = f_model\n","        self.fc = torch.nn.Linear(resnet18_output_size, 2)\n","        self.activation = torch.nn.ReLU()\n","\n","    # forward propagate input\n","    def forward(self, X):\n","        #X = self.image_processor(X, return_tensors=\"pt\").to(self.device)\n","        # print(X.pixel_value.is_cuda)\n","        X = self.f_model.features_extractor(X)\n","        X = self.activation(X)\n","        X = self.fc(X)\n","\n","        return X.softmax(dim=1)\n","\n","def Activedataloader(percent, previousPercent):\n","    firstPoint_classical     = int(previousPercent * len(activeL_classical_list))\n","    lastPoint_classical      = int(percent * len(activeL_classical_list))\n","    firstPoint_non_classical = int(previousPercent * len(activeL_non_classical_list))\n","    lastPoint_non_classical  = int(percent * len(activeL_non_classical_list))\n","\n","\n","    tensor_x = torch.Tensor(np.concatenate((activeL_classical_list[firstPoint_classical:lastPoint_classical],\n","                                       non_classical_list_MG[firstPoint_non_classical:lastPoint_non_classical]), axis=0)).to(device)\n","\n","    tensor_y = torch.Tensor(np.concatenate((np.full(lastPoint_classical - firstPoint_classical, 0),\n","                                       np.full(lastPoint_non_classical - firstPoint_non_classical,  1)), axis=0)).to(device)\n","\n","\n","    my_dataset = TensorDataset(tensor_x,tensor_y) # create your datset\n","    my_dataloader = DataLoader(my_dataset,batch_size=10, shuffle=True)\n","    return my_dataloader\n","\n","# Chemin du répertoire racine\n","import random\n","root_dir = '/content/drive/MyDrive/ColabNotebooks/mel'\n","\n","# Dictionnaire pour stocker les images par sous-dossier\n","image_dict = {}\n","\n","# Parcourir tous les sous-dossiers\n","for root, dirs, files in os.walk(root_dir):\n","    for file in files:\n","        # Construire le chemin complet du fichier\n","        file_path = os.path.join(root, file)\n","\n","        # Vérifier si le fichier est une image en fonction de l'extension (par exemple, .png)\n","        if file_path.lower().endswith(('.png', '.jpg', '.jpeg', '.gif')):\n","            # Ouvrir l'image avec Pillow\n","            image = Image.open(file_path)\n","\n","            # Convertir l'image en format JPG (si elle n'est pas déjà en JPG)\n","            if image.format != \"JPEG\":\n","                image = image.convert(\"RGB\")\n","\n","            # Obtenez le nom du sous-dossier parent\n","            parent_dir = os.path.basename(os.path.dirname(file_path))\n","\n","            # Vérifiez si le sous-dossier existe dans le dictionnaire, sinon créez-le\n","            if parent_dir not in image_dict:\n","                image_dict[parent_dir] = []\n","\n","            # Ajouter l'image à la liste du sous-dossier correspondant\n","            image = image.resize((336,219))\n","            image_dict[parent_dir].append(np.array(image))\n","\n","classical_list_MG = image_dict['classic']\n","non_classical_list_MG = image_dict['non_classic']\n","\n","percent_classical_MG = int(0.2*len(classical_list_MG))\n","percent_non_classical_MG = int(0.2*len(non_classical_list_MG))\n","\n","\n","evaluation_list_dic = []\n","for sample in classical_list_MG[:percent_classical_MG]:\n","    buffer = []\n","    buffer.append(sample)\n","    buffer.append(0)\n","    evaluation_list_dic.append(buffer)\n","\n","for sample in non_classical_list_MG[:percent_non_classical_MG]:\n","    buffer = []\n","    buffer.append(sample)\n","    buffer.append(1)\n","    evaluation_list_dic.append(buffer)\n","\n","random.shuffle(evaluation_list_dic)\n","evaluation_list = []\n","for sample in evaluation_list_dic:\n","    evaluation_list.append(sample[0])\n","\n","activeL_classical_list = classical_list_MG[percent_classical_MG:]\n","activeL_non_classical_list = non_classical_list_MG[percent_non_classical_MG:]\n"],"metadata":{"id":"OsRU8iWgp68w"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WtAWTlkSfZCm"},"source":["### Random picking"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X6UzGsJwfZCn"},"outputs":[],"source":["import os\n","import random\n","import numpy as np\n","import pandas as pd\n","import torch\n","from torch.utils.data import DataLoader, TensorDataset\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","\n","# La fonction pour le random picking et l'évaluation\n","def random_picking(modelToTrain, evaluation_list,save_dir='/content/drive/MyDrive/ColabNotebooks/models/randomPicking'):\n","\n","    # Créer un répertoire s'il n'existe pas pour y stocker les modèles\n","    if not os.path.exists(save_dir):\n","        os.makedirs(save_dir)\n","\n","    results = []\n","\n","    # Pourcentages du dataset à sélectionner\n","    percentages = [0.02, 0.05,0.10, 0.20, 0.50, 0.70, 1.00]\n","    previousPercent = 0\n","\n","    for percent in percentages:\n","        dataloader = Activedataloader(percent, previousPercent)\n","\n","        # Entraîner le nouveau modèle\n","        lr, weight_decay, epochs,timeout = 1e-5, 5e-4, 1000, 30\n","        net = torch.load(modelToTrain)\n","        loss = torch.nn.CrossEntropyLoss()\n","        optimizer = torch.optim.Adam(net.parameters(),lr=lr, weight_decay=weight_decay)\n","        net2 = train(net, dataloader, loss, optimizer, None, epochs, device, timeout=timeout)\n","        torch.save(net2, \"/content/drive/MyDrive/ColabNotebooks/models/randomPicking/random_pick_\" + str(percent) + \"_percent.pt\")\n","\n","\n","\n","        # Faire des prédictions sur la liste d'évaluation\n","        model = net2\n","        model.eval()\n","        test_data=torch.Tensor(np.array(evaluation_list)).to(device)\n","        with torch.no_grad():\n","          preds = model(test_data)\n","        output=torch.argmax(preds, dim=1)\n","\n","        # Evaluation du modèle\n","        count = 0\n","        for i in range(0,len(output)):\n","            if output[i].item() == evaluation_list_dic[i][1]:\n","                count+=1\n","        print(f\"Rand {percent} % accuracy :{(count/len(output))*100}) + %\")\n","        print(output)\n","\n","        accuracy = (count/len(output))*100, epochs\n","\n","        # Ajouter les résultats à la liste\n","        results.append([percent, accuracy])\n","        previousPercent = percent\n","        # Utiliser le modèle précédent pour poursuivre l'entraînement\n","        modelToTrain = \"/content/drive/MyDrive/ColabNotebooks/models/randomPicking/random_pick_\" + str(percent) + \"_percent.pt\"\n","\n","    # Créer un DataFrame à partir des résultats\n","    results_df = pd.DataFrame(results, columns=['Percentage', 'Accuracy'])\n","\n","    # Sauvegarder les résultats dans un fichier CSV\n","    results_csv_path = os.path.join(save_dir, 'results.csv')\n","    results_df.to_csv(results_csv_path, index=False)\n","\n","    return results_df\n","\n","# Exemple d'utilisation avec le modèle de votre choix et le dataloader\n","# active_learning_random_picking(VotreModele, Activedataloader(0.2))\n","\n"]},{"cell_type":"code","source":["random_picking(\"/content/drive/MyDrive/ColabNotebooks/model_2_Clem_trainings_longEgale_Colab.pt\", evaluation_list)"],"metadata":{"id":"cN3EzGI-s4hu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tyHgEG6DfZCn"},"source":["### Margin of Confidence"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","from urllib.request import urlopen\n","from PIL import Image\n","import torch\n","from transformers import AutoFeatureExtractor, ResNetForImageClassification, ResNetModel\n","import os\n","from PIL import Image\n","from torch.utils.data import TensorDataset, DataLoader\n","import time\n","import numpy as np\n","device = 'cuda'\n","from transformers import ResNetModel\n","import torch\n","\n","def train(net, train_dataloader, criterion, optimizer, scheduler=None, epochs=100, device=device, checkpoint_epochs=2, timeout=45):\n","    start = time.time()\n","    print(f'Training for {epochs} epochs on {device}')\n","\n","    for epoch in range(1,epochs+1):\n","        print(f\"Epoch {epoch}/{epochs}\")\n","\n","        net.train()  # put network in train mode for Dropout and Batch Normalization\n","        train_loss = torch.tensor(0., device=device)  # loss and accuracy tensors are on the GPU to avoid data transfers\n","        train_accuracy = torch.tensor(0., device=device)\n","        for X, y in train_dataloader:\n","            X = X.to(device)\n","            y = y.type(torch.LongTensor).to(device)\n","            preds = net(X)\n","            loss = criterion(preds, y)\n","\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","            with torch.no_grad():\n","                train_loss += loss * train_dataloader.batch_size\n","                train_accuracy += (torch.argmax(preds, dim=1) == y).sum()\n","\n","        if scheduler is not None:\n","            scheduler.step()\n","\n","        print(f'Training loss: {train_loss/len(train_dataloader.dataset):.2f}')\n","        print(f'Training accuracy: {100*train_accuracy/len(train_dataloader.dataset):.2f}')\n","\n","\n","        if epoch%checkpoint_epochs==0:\n","            torch.save({\n","                'epoch': epoch,\n","                'state_dict': net.state_dict(),\n","                'optimizer': optimizer.state_dict(),\n","            }, './checkpoint.pth.tar')\n","\n","        print()\n","        if((time.time() - start) >= timeout):\n","          break\n","\n","    end = time.time()\n","    print(f'Total training time: {end-start:.1f} seconds')\n","    return net\n","\n","# model definition\n","class Classifier_model(torch.nn.Module):\n","    # define model elements\n","    def __init__(self):\n","        super(Classifier_model, self).__init__()\n","        self.device = device\n","        self.image_processor = AutoFeatureExtractor.from_pretrained(\"microsoft/resnet-18\",device=self.device)\n","        self.pre_trained_model = ResNetModel.from_pretrained(\"microsoft/resnet-18\")\n","        resnet18_output_size=25088\n","        self.fc = torch.nn.Linear(resnet18_output_size, 10)\n","        self.activation = torch.nn.ReLU()\n","\n","    # forward propagate input\n","    def forward(self, X):\n","        X = self.image_processor(X, return_tensors=\"pt\").to(self.device)\n","        # print(X.pixel_value.is_cuda)\n","        X = self.pre_trained_model(**X).last_hidden_state.flatten(start_dim=1)\n","        X = self.activation(X)\n","        X = self.fc(X)\n","\n","        return X.softmax(dim=1)\n","\n","    def features_extractor(self, X):\n","        X = self.image_processor(X, return_tensors=\"pt\").to(self.device)\n","        # print(X.pixel_value.is_cuda)\n","        X = self.pre_trained_model(**X).last_hidden_state.flatten(start_dim=1)\n","\n","        return X.softmax(dim=1)\n","\n","# model definition\n","class Classifier_model_2(torch.nn.Module):\n","    # define model elements\n","    def __init__(self,f_model):\n","        super(Classifier_model_2, self).__init__()\n","        self.device = device\n","        resnet18_output_size=25088\n","        self.f_model = f_model\n","        self.fc = torch.nn.Linear(resnet18_output_size, 2)\n","        self.activation = torch.nn.ReLU()\n","\n","    # forward propagate input\n","    def forward(self, X):\n","        #X = self.image_processor(X, return_tensors=\"pt\").to(self.device)\n","        # print(X.pixel_value.is_cuda)\n","        X = self.f_model.features_extractor(X)\n","        X = self.activation(X)\n","        X = self.fc(X)\n","\n","        return X.softmax(dim=1)\n","\n","def Activedataloader(percent, previousPercent):\n","    firstPoint_classical     = int(previousPercent * len(activeL_classical_list))\n","    lastPoint_classical      = int(percent * len(activeL_classical_list))\n","    firstPoint_non_classical = int(previousPercent * len(activeL_non_classical_list))\n","    lastPoint_non_classical  = int(percent * len(activeL_non_classical_list))\n","\n","\n","    tensor_x = torch.Tensor(np.concatenate((activeL_classical_list[firstPoint_classical:lastPoint_classical],\n","                                       non_classical_list_MG[firstPoint_non_classical:lastPoint_non_classical]), axis=0)).to(device)\n","\n","    tensor_y = torch.Tensor(np.concatenate((np.full(lastPoint_classical - firstPoint_classical, 0),\n","                                       np.full(lastPoint_non_classical - firstPoint_non_classical,  1)), axis=0)).to(device)\n","\n","\n","    my_dataset = TensorDataset(tensor_x,tensor_y) # create your datset\n","    my_dataloader = DataLoader(my_dataset,batch_size=10, shuffle=True)\n","    return my_dataloader\n","\n","# Chemin du répertoire racine\n","import random\n","root_dir = '/content/drive/MyDrive/ColabNotebooks/mel'\n","\n","# Dictionnaire pour stocker les images par sous-dossier\n","image_dict = {}\n","\n","# Parcourir tous les sous-dossiers\n","for root, dirs, files in os.walk(root_dir):\n","    for file in files:\n","        # Construire le chemin complet du fichier\n","        file_path = os.path.join(root, file)\n","\n","        # Vérifier si le fichier est une image en fonction de l'extension (par exemple, .png)\n","        if file_path.lower().endswith(('.png', '.jpg', '.jpeg', '.gif')):\n","            # Ouvrir l'image avec Pillow\n","            image = Image.open(file_path)\n","\n","            # Convertir l'image en format JPG (si elle n'est pas déjà en JPG)\n","            if image.format != \"JPEG\":\n","                image = image.convert(\"RGB\")\n","\n","            # Obtenez le nom du sous-dossier parent\n","            parent_dir = os.path.basename(os.path.dirname(file_path))\n","\n","            # Vérifiez si le sous-dossier existe dans le dictionnaire, sinon créez-le\n","            if parent_dir not in image_dict:\n","                image_dict[parent_dir] = []\n","\n","            # Ajouter l'image à la liste du sous-dossier correspondant\n","            image = image.resize((336,219))\n","            image_dict[parent_dir].append(np.array(image))\n","\n","classical_list_MG = image_dict['classic']\n","non_classical_list_MG = image_dict['non_classic']\n","\n","percent_classical_MG = int(0.2*len(classical_list_MG))\n","percent_non_classical_MG = int(0.2*len(non_classical_list_MG))\n","\n","\n","evaluation_list_dic = []\n","for sample in classical_list_MG[:percent_classical_MG]:\n","    buffer = []\n","    buffer.append(sample)\n","    buffer.append(0)\n","    evaluation_list_dic.append(buffer)\n","\n","for sample in non_classical_list_MG[:percent_non_classical_MG]:\n","    buffer = []\n","    buffer.append(sample)\n","    buffer.append(1)\n","    evaluation_list_dic.append(buffer)\n","\n","random.shuffle(evaluation_list_dic)\n","evaluation_list = []\n","for sample in evaluation_list_dic:\n","    evaluation_list.append(sample[0])\n","\n","activeL_classical_list = classical_list_MG[percent_classical_MG:]\n","activeL_non_classical_list = non_classical_list_MG[percent_non_classical_MG:]\n"],"metadata":{"id":"09mt6poN8zpx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Margin Of Confidence\n","  # Prendre le full dataset\n","  # Avec le baseline, faire les prédictions\n","  # Une fois que les prédictions sont faites, Margin of Confidence\n","  # Grâce à Margin of Confidence, on obtient le dataset trié par intérêt.\n","  # On prend alors percent % de ce dataset trié et on entraîne le modèle.\n","  # On supprime ensuite ces samples du dataset original et on réitère pour le nouveau modèle obtenu.\n","\n","# Fonctions à (ré)écrire :\n","  # Active Dataloader : Doit fournir les données sélectionnées par Margin Of Confidence au modèle pour l'entraînement\n","  # MarginOfConfidence : Calcule la margin of confidence à partir d'un dataset donné\n","  # prepareData : Prépare un nouveau dataset en fonction du pourcentage à voir pour le modèle\n"],"metadata":{"id":"81WGm1_29KZ2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def MarginDataLoader(percent, previousPercent, uncertainties, dataset):\n","  \"\"\"\n","  This function is used after having determined the Margin of Confidence of the base dataset.\n","  Keywords:\n","    percent         : The percentage of the base dataset to take account of\n","    previousPercent : The previous percentage that was used the last time this function was called\n","    uncertainties   : A dictionnary containing the uncertainties associated with each sample of dataset\n","    dataset         : The updated dataset containing only unseen samples\n","  Returns:\n","    my_dataloader   : pytorch compatible data corresponding to the dataset used for the model training\n","    dataset         : The new dataset containing unseen samples\n","  \"\"\"\n","\n","  # How many samples do I have to care about this time ?\n","  difference_in_percent = percent - previousPercent\n","  lastPoint_uncertainties = int(difference_in_percent * len(uncertainties))\n","\n","  # Taking only that many samples into consideration\n","  samples_to_take = list(uncertainties.keys())[:lastPoint_uncertainties]\n","  print(samples_to_take[:10])\n","  # the indices inside the dataset of the most uncertained samples\n","  data = []\n","  for i in range(len(samples_to_take)):\n","    data.append(dataset[samples_to_take[i]])\n","\n","  dataset = np.delete(dataset, samples_to_take, axis=0)\n","\n","  # Now, we need to recreate two tensors knowing if each samples contained\n","  # inside the dataset is classical or not.\n","  new_active_classical = []\n","  new_active_non_classical = []\n","  for item in data:\n","      if any(np.array_equal(item, x) for x in activeL_classical_list):\n","          new_active_classical.append(item)\n","      else:\n","          new_active_non_classical.append(item)\n","\n","\n","  tensor_x = torch.Tensor(np.concatenate((new_active_classical, new_active_non_classical), axis = 0)).to(device)\n","  tensor_y = torch.Tensor(np.concatenate((np.full(len(new_active_classical), 0),\n","                                       np.full(len(new_active_non_classical),  1)), axis=0)).to(device)\n","\n","\n","  my_dataset = TensorDataset(tensor_x,tensor_y) # create your datset\n","  my_dataloader = DataLoader(my_dataset,batch_size=10, shuffle=True)\n","  return my_dataloader, dataset"],"metadata":{"id":"PXpyRHTiD4pX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def MarginOfConfidence(model, test_data):\n","  \"\"\"\n","  Keywords:\n","    model : The model that gives predictions\n","    data  : The dataset to base the predictions on\n","    n     : the number of best candidates to select\n","\n","  Returns:\n","    A sorted dictionnary containing the uncertainty score associated with a sample\n","  \"\"\"\n","  uncertainty_dict = {}\n","  for i in range(len(test_data)):\n","    preds = model(test_data[i])\n","    preds_sorted = np.sort(preds[0].cpu().detach().numpy())\n","    uncertainty_dict[i] = (preds_sorted[0] - preds_sorted[1])\n","  res = dict(sorted(uncertainty_dict.items(),\n","                    key = lambda x: x[1], reverse = True))\n","  for key in list(res.keys())[:10]:\n","      print(f\"{key}: {res[key]}\")\n","  return res"],"metadata":{"id":"rNbQ6GVnD-14"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"St5iHgGYfZCn"},"outputs":[],"source":["import os\n","import random\n","import numpy as np\n","import pandas as pd\n","import torch\n","from torch.utils.data import DataLoader, TensorDataset\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","\n","def marginOfConfidence_Train(modelToTrain, evaluation_list,save_dir='/content/drive/MyDrive/ColabNotebooks/models/MarginOfConfidence'):\n","\n","    # Créer un répertoire s'il n'existe pas pour y stocker les modèles\n","    if not os.path.exists(save_dir):\n","        os.makedirs(save_dir)\n","\n","    results = []\n","\n","    # Pourcentages du dataset à sélectionner\n","    percentages = [0.02, 0.05,0.10, 0.20, 0.50, 0.70, 1.00]\n","    previousPercent = 0\n","\n","    dataset = [activeL_classical_list, activeL_non_classical_list]\n","\n","    for percent in percentages:\n","        print(f\"\"\"  for item in data:\n","      if any(np.array_equal(item, x) for x in activeL_classical_list):\n","          new_active_classical.append(item)\n","      else:\n","          new_active_non_classical.append(item)\n","\n","        #############################\n","        #         NEW ROUND         #\n","        #     percent = {percent}   #\n","        #############################\n","        \"\"\")\n","        lr, weight_decay, epochs,timeout = 1e-5, 5e-4, 1000, 30\n","        net = torch.load(modelToTrain)\n","        loss = torch.nn.CrossEntropyLoss()\n","        optimizer = torch.optim.Adam(net.parameters(),lr=lr, weight_decay=weight_decay)\n","\n","        # Active Learning\n","        print(f\"\"\"\n","        #############################\n","        #    Calculating Margin     #\n","        #############################\n","        \"\"\")\n","        uncertainties = MarginOfConfidence(net, dataset)\n","        dataloader, dataset = MarginDataLoader(percent, previousPercent, uncertainties, dataset)\n","\n","        print(f\"\"\"\n","        #############################\n","        #       Begin Training      #\n","        #############################\n","        \"\"\")\n","\n","        net2 = train(net, dataloader, loss, optimizer, None, epochs, device, timeout=timeout)\n","        torch.save(net2, \"/content/drive/MyDrive/ColabNotebooks/models/MarginOfConfidence/margin_confidence_\" + str(percent) + \"_percent.pt\")\n","\n","\n","\n","        # Faire des prédictions sur la liste d'évaluation\n","        model = net2\n","        model.eval()\n","        test_data=torch.Tensor(np.array(evaluation_list)).to(device)\n","        with torch.no_grad():\n","          preds = model(test_data)\n","        output=torch.argmax(preds, dim=1)\n","\n","        # Evaluation du modèle\n","        count = 0\n","        for i in range(0,len(output)):\n","            if output[i].item() == evaluation_list_dic[i][1]:\n","                count+=1\n","        print(f\"Margin_Confidence {percent} % accuracy :{(count/len(output))*100}) + %\")\n","        print(output)\n","\n","        accuracy = (count/len(output))*100, epochs\n","\n","        # Ajouter les résultats à la liste\n","        results.append([percent, accuracy])\n","        previousPercent = percent\n","        # Utiliser le modèle précédent pour poursuivre l'entraînement\n","        modelToTrain = \"/content/drive/MyDrive/ColabNotebooks/models/MarginOfConfidence/margin_confidence_\" + str(percent) + \"_percent.pt\"\n","\n","    # Créer un DataFrame à partir des résultats\n","    results_df = pd.DataFrame(results, columns=['Percentage', 'Accuracy'])\n","\n","    # Sauvegarder les résultats dans un fichier CSV\n","    results_csv_path = os.path.join(save_dir, 'results.csv')\n","    results_df.to_csv(results_csv_path, index=False)\n","\n","    return results_df\n"]},{"cell_type":"code","source":["marginOfConfidence_Train(\"/content/drive/MyDrive/ColabNotebooks/model_2_Clem_trainings_longEgale_Colab.pt\", evaluation_list)"],"metadata":{"id":"gZDpRn5eehl_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gXRd-VZBfZCn"},"source":["### Ratio Of Confidence"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xcpBY4uZfZCn"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"},"orig_nbformat":4,"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}